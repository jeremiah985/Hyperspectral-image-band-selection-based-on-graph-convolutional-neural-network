{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import scipy.io as scio \n",
    "import scipy.io as sio\n",
    "import pandas as pd\n",
    "from tf_utils import random_mini_batches\n",
    "from tensorflow.python.framework import ops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 原始版本目前准确率最高"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建占位符时增加L2，占位符就是告诉你这里有一个空位置，但是还不知道数据的类型是什么。。\n",
    "def create_placeholders(n_x):\n",
    "    isTraining = tf.placeholder_with_default(True, shape=())\n",
    "    # 输入数据的特征                    \n",
    "    x_in = tf.placeholder(tf.float32, [None, n_x], name=\"x_in\")\n",
    "    # 图的拉普拉斯矩阵L1（像素维度）\n",
    "    lap1 = tf.placeholder(tf.float32, [None, None], name=\"lap1\")\n",
    "    # 波段方向上的Laplacian L2（波段维度）\n",
    "    lap2 = tf.placeholder(tf.float32, [n_x, n_x], name=\"lap2\")\n",
    "    return x_in, lap1, lap2, isTraining\n",
    "\n",
    "#这里定义的是一个初始化参数的函数，代表创建神经网络模型中的可训练参数\n",
    "def initialize_parameters(n_x):\n",
    "    tf.set_random_seed(1)\n",
    "    #在这里新传入一个变量用来代替不同的维度\n",
    "    x_w1 = tf.get_variable(\"x_w1\", [n_x, n_x], initializer=tf.contrib.layers.xavier_initializer(seed=1))\n",
    "    x_b1 = tf.get_variable(\"x_b1\", [n_x], initializer=tf.zeros_initializer())\n",
    "    x_w2 = tf.get_variable(\"x_w2\", [n_x, n_x], initializer=tf.contrib.layers.xavier_initializer(seed=1))\n",
    "    x_b2 = tf.get_variable(\"x_b2\", [n_x], initializer=tf.zeros_initializer())\n",
    "    parameters = {\n",
    "        \"x_w1\": x_w1,\n",
    "        \"x_b1\": x_b1,\n",
    "        \"x_w2\": x_w2,\n",
    "        \"x_b2\": x_b2\n",
    "    }\n",
    "    return parameters\n",
    "\n",
    "# 新的GCN_layer函数，实现L1 * X * L2 * W\n",
    "def GCN_layer(x_in, L1, L2, weights):\n",
    "    # x_in  : (N, n_x)\n",
    "    # L1    : (N, N)\n",
    "    # L2    : (n_x, n_x)\n",
    "    # weights : (n_x, n_y)\n",
    "\n",
    "    # 先对空间维度进行卷积: L1 * X_in     500* 220\n",
    "    x_mid1 = tf.matmul(L1, x_in)         # (N, n_x)\n",
    "\n",
    "    # 再对波段维度进行卷积: (L1 * X) * L2  220*220\n",
    "    x_mid2 = tf.matmul(x_mid1, L2)       # (N, n_x)\n",
    "\n",
    "    # 最后乘上权重矩阵: (L1 * X * L2) * W  220*220\n",
    "    x_out = tf.matmul(x_mid2, weights)   # (N, n_y)\n",
    "\n",
    "    return x_out\n",
    "\n",
    "def mynetwork(x, parameters, Lap1, Lap2, isTraining, momentums=0.9):\n",
    "    with tf.name_scope(\"x_layer_1\"):\n",
    "        x_z1_bn = tf.layers.batch_normalization(x, momentum=momentums, training=isTraining)\n",
    "        x_z1 = GCN_layer(x_z1_bn, Lap1, Lap2, parameters['x_w1']) + parameters['x_b1']\n",
    "        x_z1_bn = tf.layers.batch_normalization(x_z1, momentum=momentums, training=isTraining)\n",
    "        x_a1 = tf.nn.relu(x_z1_bn)\n",
    "\n",
    "    with tf.name_scope(\"x_layer_2\"):\n",
    "        x_z2_bn = tf.layers.batch_normalization(x_a1, momentum=momentums, training=isTraining)\n",
    "        x_z2 = GCN_layer(x_z2_bn, Lap1, Lap2, parameters['x_w2']) + parameters['x_b2']\n",
    "#                      500*128 500*500 220*220 \n",
    "    # L1正则化\n",
    "    l1_loss = tf.reduce_sum(tf.abs(parameters['x_w2']))\n",
    "    return x_z2, l1_loss\n",
    "\n",
    "def mynetwork_optimization(output, x_in, l1_loss, reg, learning_rate, global_step):\n",
    "    with tf.name_scope(\"cost\"):\n",
    "        reconstruction_loss = tf.reduce_mean(tf.square(output - x_in))\n",
    "        cost = reconstruction_loss + reg * l1_loss\n",
    "    with tf.name_scope(\"optimization\"):\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost, global_step=global_step)\n",
    "    return cost, optimizer\n",
    "\n",
    "def train_mynetwork(x_all, L_all, L2_all, learning_rate=0.001, beta_reg=0.001, num_epochs=200, print_cost=True):\n",
    "    ops.reset_default_graph()\n",
    "    (m, n_x) = x_all.shape\n",
    "    costs = []\n",
    "    \n",
    "    #创建占位符\n",
    "    x_in, lap1, lap2, isTraining = create_placeholders(n_x)\n",
    "    #创建参数\n",
    "    parameters = initialize_parameters(n_x)\n",
    "\n",
    "    with tf.name_scope(\"network\"):\n",
    "        #前向传播\n",
    "        output, l1_loss = mynetwork(x_in, parameters, lap1, lap2, isTraining)\n",
    "\n",
    "    global_step = tf.Variable(0, trainable=False)\n",
    "    with tf.name_scope(\"optimization\"):\n",
    "        cost, optimizer = mynetwork_optimization(output, x_in, l1_loss, beta_reg, learning_rate, global_step)\n",
    "\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        for epoch in range(num_epochs + 1):\n",
    "            _ , epoch_cost = sess.run([optimizer, cost], feed_dict={x_in: x_all, lap1: L_all, lap2: L2_all, isTraining: True})\n",
    "            if print_cost and epoch % 50 == 0:\n",
    "                print(\"Epoch %i: Cost: %f\" % (epoch, epoch_cost))\n",
    "            if print_cost and epoch % 5 == 0:\n",
    "                costs.append(epoch_cost)\n",
    "\n",
    "        plt.plot(np.squeeze(costs))\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('iterations (per 5 epochs)')\n",
    "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "        plt.show()\n",
    "   \n",
    "        band_scores = sess.run(parameters['x_w2'])\n",
    "        print(\"Training completed!\")\n",
    "\n",
    "        return parameters, band_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALL_X: (500, 220)\n",
      "ALL_L: (500, 500)\n",
      "ALL_L2: (220, 220)\n"
     ]
    }
   ],
   "source": [
    "import scipy.io as scio\n",
    "\n",
    "# 加载数据\n",
    "ALL_X = scio.loadmat('D:\\\\vscode\\\\HSI\\\\myGCN\\\\predata\\\\X.mat')['X']  # 去掉 .todense()\n",
    "ALL_X = np.transpose(ALL_X)  # 或者用 ALL_X.T\n",
    "ALL_L = scio.loadmat('D:\\\\vscode\\\\HSI\\\\myGCN\\\\predata\\\\LX.mat')['LX']  # 同样去掉 .todense()\n",
    "ALL_L2 = scio.loadmat('D:\\\\vscode\\\\HSI\\\\myGCN\\\\predata\\\\LX2.mat')['LX2']  # 去掉 .todense()\n",
    "\n",
    "print(\"ALL_X:\", ALL_X.shape)\n",
    "print(\"ALL_L:\", ALL_L.shape)\n",
    "print(\"ALL_L2:\", ALL_L2.shape)\n",
    "\n",
    "\n",
    "ALL_L = ALL_L.toarray()  # 转换为密集矩阵\n",
    "ALL_L2 = ALL_L2.toarray()  # 转换为密集矩阵\n",
    "\n",
    "\n",
    "# \n",
    "# ALL_X: (500, 220)\n",
    "# ALL_L: (500, 500)\n",
    "# ALL_L2: (220, 220)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Dimensions must be equal, but are 128 and 220 for 'network/x_layer_2/MatMul_1' (op: 'MatMul') with input shapes: [?,128], [220,220].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jere\\.conda\\envs\\virtf1cpu\\lib\\site-packages\\tensorflow\\python\\framework\\common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[1;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, require_shape_fn)\u001b[0m\n\u001b[0;32m    685\u001b[0m           \u001b[0mgraph_def_version\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode_def_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shapes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 686\u001b[1;33m           input_tensors_as_shapes, status)\n\u001b[0m\u001b[0;32m    687\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jere\\.conda\\envs\\virtf1cpu\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[0;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 473\u001b[1;33m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[0;32m    474\u001b[0m     \u001b[1;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Dimensions must be equal, but are 128 and 220 for 'network/x_layer_2/MatMul_1' (op: 'MatMul') with input shapes: [?,128], [220,220].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-72204a370eb0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mband_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_mynetwork\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mALL_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mALL_L\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mALL_L2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.001\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta_reg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.001\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprint_cost\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# 保存波段得分\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0msio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msavemat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'band_scores.mat'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'band_scores'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mband_scores\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-de5bdacb339d>\u001b[0m in \u001b[0;36mtrain_mynetwork\u001b[1;34m(x_all, L_all, L2_all, learning_rate, beta_reg, num_epochs, print_cost)\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"network\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m         \u001b[1;31m#前向传播\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m         \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml1_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmynetwork\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_in\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlap1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlap2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0misTraining\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m     \u001b[0mglobal_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-de5bdacb339d>\u001b[0m in \u001b[0;36mmynetwork\u001b[1;34m(x, parameters, Lap1, Lap2, isTraining, momentums)\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"x_layer_2\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[0mx_z2_bn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_normalization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_a1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmomentums\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0misTraining\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m         \u001b[0mx_z2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGCN_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_z2_bn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLap1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLap2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'x_w2'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'x_b2'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;31m# L1正则化\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-de5bdacb339d>\u001b[0m in \u001b[0;36mGCN_layer\u001b[1;34m(x_in, L1, L2, weights)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[1;31m# 再对波段维度进行卷积: (L1 * X) * L2  220*220\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m     \u001b[0mx_mid2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_mid1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mL2\u001b[0m\u001b[1;33m)\u001b[0m       \u001b[1;31m# (N, n_x)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[1;31m# 最后乘上权重矩阵: (L1 * X * L2) * W  220*220\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jere\\.conda\\envs\\virtf1cpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mmatmul\u001b[1;34m(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, name)\u001b[0m\n\u001b[0;32m   1889\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1890\u001b[0m       return gen_math_ops._mat_mul(\n\u001b[1;32m-> 1891\u001b[1;33m           a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n\u001b[0m\u001b[0;32m   1892\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1893\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jere\\.conda\\envs\\virtf1cpu\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36m_mat_mul\u001b[1;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[0;32m   2434\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[0;32m   2435\u001b[0m         \u001b[1;34m\"MatMul\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtranspose_a\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtranspose_b\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtranspose_b\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2436\u001b[1;33m         name=name)\n\u001b[0m\u001b[0;32m   2437\u001b[0m     \u001b[0m_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2438\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jere\\.conda\\envs\\virtf1cpu\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    785\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[0;32m    786\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 787\u001b[1;33m                          op_def=op_def)\n\u001b[0m\u001b[0;32m    788\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jere\\.conda\\envs\\virtf1cpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[0;32m   2956\u001b[0m         op_def=op_def)\n\u001b[0;32m   2957\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcompute_shapes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2958\u001b[1;33m       \u001b[0mset_shapes_for_outputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2959\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_add_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2960\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_record_op_seen_by_control_dependencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jere\\.conda\\envs\\virtf1cpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mset_shapes_for_outputs\u001b[1;34m(op)\u001b[0m\n\u001b[0;32m   2207\u001b[0m       \u001b[0mshape_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2208\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2209\u001b[1;33m   \u001b[0mshapes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshape_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2210\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mshapes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2211\u001b[0m     raise RuntimeError(\n",
      "\u001b[1;32mc:\\Users\\jere\\.conda\\envs\\virtf1cpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mcall_with_requiring\u001b[1;34m(op)\u001b[0m\n\u001b[0;32m   2157\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2158\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2159\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mcall_cpp_shape_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequire_shape_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2160\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2161\u001b[0m   \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jere\\.conda\\envs\\virtf1cpu\\lib\\site-packages\\tensorflow\\python\\framework\\common_shapes.py\u001b[0m in \u001b[0;36mcall_cpp_shape_fn\u001b[1;34m(op, require_shape_fn)\u001b[0m\n\u001b[0;32m    625\u001b[0m     res = _call_cpp_shape_fn_impl(op, input_tensors_needed,\n\u001b[0;32m    626\u001b[0m                                   \u001b[0minput_tensors_as_shapes_needed\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 627\u001b[1;33m                                   require_shape_fn)\n\u001b[0m\u001b[0;32m    628\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    629\u001b[0m       \u001b[1;31m# Handles the case where _call_cpp_shape_fn_impl calls unknown_shape(op).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jere\\.conda\\envs\\virtf1cpu\\lib\\site-packages\\tensorflow\\python\\framework\\common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[1;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, require_shape_fn)\u001b[0m\n\u001b[0;32m    689\u001b[0m       \u001b[0mmissing_shape_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    690\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 691\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    692\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    693\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mmissing_shape_fn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Dimensions must be equal, but are 128 and 220 for 'network/x_layer_2/MatMul_1' (op: 'MatMul') with input shapes: [?,128], [220,220]."
     ]
    }
   ],
   "source": [
    "parameters, band_scores = train_mynetwork(ALL_X, ALL_L, ALL_L2, learning_rate=0.001, beta_reg=0.001, num_epochs=200, print_cost=True)\n",
    "\n",
    "# 保存波段得分\n",
    "sio.savemat('band_scores.mat', {'band_scores': band_scores})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "选择的波段索引： [176 141 148 182  94   3  18   5 194  47 208  32 107  91  14 101  66 175\n",
      "  30 173  36 106 108  49 192 198  29 217 149 212  13 110  62 128  73 104\n",
      "   4 189  92  68 159 134  42 197  46 136 209 112  33  57]\n",
      "选择的波段数据： [[ 0.04726335  0.03636783  0.05962943 ...  0.0567863   0.04616272\n",
      "   0.03840406]\n",
      " [ 0.04530458  0.03132842  0.03912318 ...  0.04719875 -0.00559831\n",
      "  -0.06138576]\n",
      " [ 0.01762298  0.00969087  0.01321147 ...  0.01650228 -0.06273087\n",
      "   0.05633597]\n",
      " ...\n",
      " [ 0.05557523 -0.07684766 -0.08114755 ... -0.10135758 -0.02720143\n",
      "   0.0433742 ]\n",
      " [-0.02985972 -0.00970482 -0.01138071 ... -0.03293665  0.0673983\n",
      "  -0.03845708]\n",
      " [ 0.02250978  0.01982882  0.01583971 ...  0.05139302 -0.0441799\n",
      "  -0.0208163 ]]\n"
     ]
    }
   ],
   "source": [
    "# 选择得分最高的K个波段\n",
    "K = 50\n",
    "band_importance = np.sum(np.abs(band_scores), axis=0)\n",
    "#为什么要相加\n",
    "top_k_indices = np.argsort(band_importance)[-K:]\n",
    "selected_bands = ALL_X[:, top_k_indices]\n",
    "\n",
    "# 保存选择的波段\n",
    "sio.savemat('selected_bands.mat', {'selected_bands': selected_bands})\n",
    "\n",
    "# 打印选择的波段\n",
    "print(\"选择的波段索引：\", top_k_indices)\n",
    "print(\"选择的波段数据：\", selected_bands)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virtf1cpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
